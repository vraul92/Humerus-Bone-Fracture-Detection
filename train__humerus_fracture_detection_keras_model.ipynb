{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications import densenet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../anaconda3/BoneFractureDetectionMURA/MURA-v1.1/train/XR_FOREARM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path(root_path = train_path):\n",
    "\t\n",
    "\t'''\n",
    "\tload MURA dataset\n",
    "\n",
    "\t'''\n",
    "\tPath = []\n",
    "\tlabels = []\n",
    "\tfor root,dirs,files in os.walk(root_path): #Read all pictures, os.walk Return to iterator genertor Traverse all files\n",
    "\t\tfor name in files:\n",
    "\t\t\tif str(name[0]) != '.':\n",
    "\t\t\t\tpath_1 = os.path.join(root,name)\n",
    "\t\t\t\tPath.append(path_1)\n",
    "\n",
    "\t\t\t\n",
    "\t\t\tif root.split('_')[-1]=='positive':  #positive Label is 1, otherwise 0\n",
    "\t\t\t\tlabels+=[1]  #Last level directory file patient11880\\\\study1_negative\\\\image3.png\n",
    "\t\t\telif root.split('_')[-1]=='negative':\n",
    "\t\t\t\tlabels+=[0]\n",
    "\n",
    "# \tlabels = np.asarray(labels)\n",
    "\treturn Path, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "X_path, X_label = load_path()\n",
    "\n",
    "print(X_label[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = X_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1825\n",
      "1825\n",
      "../anaconda3/BoneFractureDetectionMURA/MURA-v1.1/train/XR_FOREARM/patient09592/study1_negative/image1.png\n",
      "../anaconda3/BoneFractureDetectionMURA/MURA-v1.1/train/XR_FOREARM/patient09592/study1_negative/image2.png\n",
      "../anaconda3/BoneFractureDetectionMURA/MURA-v1.1/train/XR_FOREARM/patient03894/study1_negative/image1.png\n"
     ]
    }
   ],
   "source": [
    "print(len(X_path))\n",
    "print(len(X_label))\n",
    "for i in range(3):\n",
    "    print(X_path[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotation_flip(image,size = 224):\n",
    "\tif random.randint(0,1):\n",
    "\t\timage = cv2.flip(image,1) # 1-->horizontal flip 0-->Vertical flip -1-->Horizontal and vertical\n",
    "\n",
    "\tif random.randint(0,1):\n",
    "\t\tangle = random.randint(-30,30)\n",
    "\t\tM = cv2.getRotationMatrix2D((size/2,size/2),angle,1)\n",
    "\t\t#The third parameter: the size of the transformed image\n",
    "\t\timage = cv2.warpAffine(image,M,(size,size))\n",
    "\treturn image\n",
    "\n",
    "def load_image(Path = X_path, size = 224):\n",
    "    \n",
    "\tImages = []\n",
    "\tfor path in Path:\n",
    "\t\ttry:\n",
    "\t\t\timage = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "\t\t\timage = cv2.resize(image,(size,size))\n",
    "\t\t\timage = random_rotation_flip(image,size)\n",
    "\t\t\tImages.append(image)\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(str(e))\n",
    "\n",
    "\tImages = np.asarray(Images).astype('float32')\n",
    "\n",
    "\tmean = np.mean(Images)\t\t\t#normalization\n",
    "\tstd = np.std(Images)\n",
    "\tImages = (Images - mean) / std\n",
    "\t\n",
    "# \tif K.image_data_format() == \"channels_first\":\n",
    "# \t\tImages = np.expand_dims(Images,axis=1)\t\t   #Extended dimension 1\n",
    "# \tif K.image_data_format() == \"channels_last\":\n",
    "# \t\tImages = np.expand_dims(Images,axis=3)             #Extended dimension 3(usebackend tensorflow:aixs=3; theano:axixs=1) \n",
    "\treturn Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1825, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a greyscale array to rgb by extending the last axis from 1 to 3\n",
    "# X_train = np.repeat(X_train_greyscale, 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "c = 5\n",
    "# for i in range(c):\n",
    "#     plt.subplot(5 / c+1, c, i + 1)\n",
    "#     plt.imshow(images_by_pixel_values)\n",
    "# abc = X_train[0][0:5][0:5,0:5][0:5,0:5]\n",
    "# print(abc)\n",
    "# print(abc.shape)\n",
    "# for i in range(5):\n",
    "#     plt.subplot(5 / c+1, c, i + 1)\n",
    "#     plt.imshow(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1825\n",
      "1825\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(X_train)\n",
    "print(len(X_label))\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToOneHot(vector, num_classes=None):\n",
    "    \"\"\"\n",
    "    Converts an input 1-D vector of integers into an output\n",
    "    2-D array of one-hot vectors, where an i'th input value\n",
    "    of j will set a '1' in the i'th row, j'th column of the\n",
    "    output array.\n",
    "\n",
    "    Example:\n",
    "        v = np.array((1, 0, 4))\n",
    "        one_hot_v = convertToOneHot(v)\n",
    "        print one_hot_v\n",
    "\n",
    "        [[0 1 0 0 0]\n",
    "         [1 0 0 0 0]\n",
    "         [0 0 0 0 1]]\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(vector, np.ndarray)\n",
    "    assert len(vector) > 0\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(vector)+1\n",
    "    else:\n",
    "        assert num_classes > 0\n",
    "        assert num_classes >= np.max(vector)\n",
    "\n",
    "    result = np.zeros(shape=(len(vector), num_classes))\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result.astype(int)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert list to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_train)\n",
    "y_raw = np.array(X_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode the training labels\n",
    "y = convertToOneHot(y_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x647db0410>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        ...,\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305]],\n",
       "\n",
       "       [[-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        ...,\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305]],\n",
       "\n",
       "       [[-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        ...,\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        ...,\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305]],\n",
       "\n",
       "       [[-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        ...,\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305]],\n",
       "\n",
       "       [[-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        ...,\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305],\n",
       "        [-1.0181305, -1.0181305, -1.0181305]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images is:  (1825, 224, 224, 3)\n",
      "Shape of labels is:  (1825, 2)\n",
      "(224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train images is: \", X.shape)\n",
    "print(\"Shape of labels is: \", y.shape)\n",
    "print(X[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive in training: 852\n",
      "Negative in training: 515\n",
      "Train pos/neg ratio: 1.654368932038835\n",
      "Positive in test: 311\n",
      "Negative in test: 145\n",
      "Test pos/neg ratio: 2.1448275862068966\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state=3)\n",
    "\n",
    "# pickle_out = open(\"X_train\", \"wb\")\n",
    "# pickle.dump(X_train, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"X_val\", \"wb\")\n",
    "# pickle.dump(X_val, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"y_train\", \"wb\")\n",
    "# pickle.dump(y_train, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"y_val\", \"wb\")\n",
    "# pickle.dump(y_val, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "\n",
    "#Test the split of 0's and 1's in training and validation labels\n",
    "pos_train =0\n",
    "neg_train = 0\n",
    "pos_val = 0\n",
    "neg_val = 0\n",
    "\n",
    "\n",
    "for i in range(1,len(y_train)):\n",
    "    if y_train[i][0] == 1:\n",
    "        pos_train = pos_train + 1\n",
    "    else:\n",
    "        neg_train = neg_train + 1\n",
    "        \n",
    "for i in range(1,len(y_val)):\n",
    "    if y_val[i][0] == 1:\n",
    "        pos_val = pos_val + 1\n",
    "    else:\n",
    "        neg_val = neg_val + 1\n",
    "        \n",
    "print(\"Positive in training: \" + str(pos_train))\n",
    "print(\"Negative in training: \" + str(neg_train))\n",
    "print(\"Train pos/neg ratio: \" + str (pos_train/neg_train))\n",
    "      \n",
    "print(\"Positive in test: \" + str(pos_val))\n",
    "print(\"Negative in test: \" + str(neg_val))\n",
    "print(\"Test pos/neg ratio: \" + str (pos_val/neg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training images is:  (1368, 224, 224, 3)\n",
      "Shape of Validation images is:  (457, 224, 224, 3)\n",
      "Shape of Training labels is:  (1368, 2)\n",
      "Shape of Validation labels is:  (457, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training images is: \", X_train.shape)\n",
    "print(\"Shape of Validation images is: \", X_val.shape)\n",
    "print(\"Shape of Training labels is: \", y_train.shape)\n",
    "print(\"Shape of Validation labels is: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  1368\n",
      "Number of validation images:  457\n"
     ]
    }
   ],
   "source": [
    "ntrain = len(X_train)\n",
    "print(\"Number of training images: \", ntrain)\n",
    "nval = len(X_val)\n",
    "print(\"Number of validation images: \",nval)\n",
    "\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conv_factory(x, nb_filter, dropout_rate=None, weight_decay=1E-4):\n",
    "#     \"\"\"Apply BatchNorm, Relu 3x3Conv2D, optional dropout\n",
    "\n",
    "#     :parameter x: Input keras network\n",
    "#     :parameter concat_axis: int -- index of contatenate axis\n",
    "#     :parameter nb_filter: int -- number of filters\n",
    "#     :parameter dropout_rate: int -- dropout rate\n",
    "#     :parameter weight_decay: int -- weight decay factor\n",
    "\n",
    "#     :returns: keras network with b_norm, relu and Conv2D added\n",
    "#     :return type: keras network\n",
    "#     \"\"\"\n",
    "#     x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Conv2D(nb_filter, (1, 1), kernel_initializer=\"he_uniform\", padding=\"same\", use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "#     x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Conv2D(nb_filter, (3, 3), kernel_initializer=\"he_uniform\", padding=\"same\", use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "#     if dropout_rate:\n",
    "#         x = Dropout(dropout_rate)(x)\n",
    "\n",
    "#     return x\n",
    "\n",
    "# def denseblock(x, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1E-4):\n",
    "#     \"\"\"\n",
    "#     Build a denseblock where the output of each conv_factory is fed to subsequent ones\n",
    "\n",
    "#     :parameter x: keras model\n",
    "#     :parameter concat_axis: int -- index of contatenate axis\n",
    "#     :parameter nb_layers: int -- the number of layers of conv_factory to append to the model.\n",
    "#     :parameter nb_filter: int -- number of filters\n",
    "#     :parameter dropout_rate: int -- dropout rate\n",
    "#     :parameter weight_decay: int -- weight decay factor\n",
    "\n",
    "#     :returns: keras model with nb_layers of conv_factory appended\n",
    "#     :return type: keras model\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     list_feat = [x]\n",
    "\n",
    "#     for i in range(nb_layers):\n",
    "#         x = conv_factory(x, growth_rate,\n",
    "#                          dropout_rate, weight_decay)\n",
    "#         list_feat.append(x)\n",
    "#         x = Concatenate()(list_feat)\n",
    "#         nb_filter += growth_rate\n",
    "#         #print (nb_filter)\n",
    "\n",
    "#     return x, nb_filter\n",
    "\n",
    "# def transition(x, nb_filter, dropout_rate=None, weight_decay=1E-4):\n",
    "#     \"\"\"Apply BatchNorm, Relu 1x1Conv2D, optional dropout and Maxpooling2D\n",
    "\n",
    "#     :parameter x: keras model\n",
    "#     :parameter concat_axis: int -- index of contatenate axis\n",
    "#     :parameter nb_filter: int -- number of filters\n",
    "#     :parameter dropout_rate: int -- dropout rate\n",
    "#     :parameter weight_decay: int -- weight decay factor\n",
    "\n",
    "#     :returns: model\n",
    "#     :return type: keras model, after applying batch_norm, relu-conv, dropout, maxpool\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Conv2D(nb_filter, (1, 1), kernel_initializer=\"he_uniform\", padding=\"same\", use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "#     if dropout_rate:\n",
    "#         x = Dropout(dropout_rate)(x)\n",
    "#     x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "#     return x\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# nb_classes = 1\n",
    "# img_dim = [256,256,3]\n",
    "# nb_filter = 3\n",
    "# nb_dense_block = 4\n",
    "# growth_rate = 32\n",
    "# dropout_rate = 0.5\n",
    "# depth = 34\n",
    "# weight_decay = 0.01\n",
    "\n",
    "# model_input = Input(shape=img_dim)\n",
    "\n",
    "# assert (depth - 4) % 3 == 0, \"Depth must be 3 N + 4\"\n",
    "\n",
    "# # layers in each dense block\n",
    "# nb_layers = int((depth - 4) / 3)\n",
    "\n",
    "# # Initial convolution\n",
    "# x = Conv2D(nb_filter, (7, 7), strides=(2, 2), kernel_initializer=\"he_uniform\", padding=\"same\", name=\"initial_conv2D\", use_bias=False, kernel_regularizer=l2(weight_decay))(model_input)\n",
    "\n",
    "# # Add dense blocks\n",
    "# nb_layers1 = [6,12,32,32,48,32,48,64,32]  #3*3 convolutional layer of each denseblock ，\n",
    "# for block_idx in range(nb_dense_block - 1):\n",
    "#     x, nb_filter = denseblock(x, nb_layers1[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "#     # add transition\n",
    "#     x = transition(x,nb_filter, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "# # The last denseblock does not have a transition\n",
    "# x, nb_filter = denseblock(x, nb_layers1[nb_dense_block-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "# x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = GlobalAveragePooling2D(data_format=K.image_data_format())(x)\n",
    "# x = Dense(nb_classes, activation='sigmoid', kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "# head_model = models.Model(inputs=[model_input], outputs=[x], name=\"DenseNet\")\n",
    "###########################################################################################\n",
    "\n",
    "##########################################################################################\n",
    "#number of classes in your dataset e.g. 20\n",
    "# num_classes = 1\n",
    "\n",
    "# base_model = tensorflow.keras.applications.VGG16(include_top = False, weights = 'imagenet',  input_shape = [256, 256, 3], pooling = max, classes = 2)\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# x = base_model.output\n",
    "# x = Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(256,256,3))(x)\n",
    "# x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(4096, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "# predictions = Dense(num_classes, activation = 'relu')(x)\n",
    "\n",
    "# head_model = models.Model(base_model.input, predictions)\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "# dense201_model = densenet.DenseNet201(include_top = False, weights = 'imagenet',  input_shape = [512, 512, 3], pooling = max)\n",
    "# # Dont train existing weights\n",
    "# for layer in dense201_model.layers:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "# x = Flatten()(dense201_model.output)\n",
    "# #### No dropout layer added\n",
    "\n",
    "\n",
    "# prediction = Dense(1, activation = 'relu')(x)\n",
    "# model = models.Model(inputs = dense201_model.input, outputs = prediction)\n",
    "\n",
    "# head_model.get_config()\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "# inception = InceptionV3(include_top=False, weights='imagenet', input_tensor=inp, input_shape=IMG_SIZE, pooling='avg')\n",
    "# # for layer in inception.layers:\n",
    "# #     layer.trainable = False\n",
    "\n",
    "# input_layer = inception.inputs\n",
    "# # last_layer = inception.get_layer(index=-1)\n",
    "# # inception_layers = models.Model(inputs=input_layer, outputs=last_layer.output)\n",
    "# # print(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2, DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from glob import glob\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_preprocessed = preprocess_input(X_train)\n",
    "# x_val_preprocessed = preprocess_input(X_val)\n",
    "# y_train_preprocessed = preprocess_input(y_train)\n",
    "# y_val_preprocessed = preprocess_input(y_val)\n",
    "\n",
    "\n",
    "# x_train_features = inception_layers.predict(X_train)\n",
    "# x_val_features = inception_layers.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224,3)\n",
    "inp = Input(IMG_SIZE)\n",
    "\n",
    "densenet = DenseNet121(include_top=False, weights='imagenet', input_tensor=inp, input_shape=IMG_SIZE, pooling='max')\n",
    "input_layer=densenet.inputs\n",
    "\n",
    "x = densenet.output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# Create your own model\n",
    "feature_model = models.Model(input_layer, preds)\n",
    "\n",
    "feature_model.trainable = True\n",
    "#optimizer : RMS Prop\n",
    "#loss : binary_crossentropy because it is a binary classification\n",
    "# lr_schedule = tensorflow.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-3,\n",
    "#     decay_rate=0.9)\n",
    "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov = True, name=\"SGD\")\n",
    "\n",
    "# I let the last 3 blocks train\n",
    "for layer in feature_model.layers[:-60]:\n",
    "    layer.trainable = False\n",
    "for layer in feature_model.layers[-60:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "feature_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range = 30,\n",
    "                                  width_shift_range=0.3,\n",
    "                                  height_shift_range=0.3,\n",
    "                                  shear_range=0.3,\n",
    "                                  zoom_range=0.3,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  data_format='channels_last')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the image generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6012 (pid 9556), started 0:54:22 ago. (Use '!kill 9556' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d6fbbc5b1374778\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d6fbbc5b1374778\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6012;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /log/mobilenetv2/50\\ Layers\\ Trained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\n",
    "modelcheckpoint = tensorflow.keras.callbacks.ModelCheckpoint(filepath='keras_mobilenetv2_model.{epoch:02d}-{val_loss:.2f}.h5', save_best_only=True, monitor='val_acc', mode='max')\n",
    "\n",
    "log_dir = \"./log/mobilenetv2/50 Layers Trained/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tensorflow.keras.callbacks.TensorBoard(log_dir, histogram_freq=1, write_graph=True, update_freq='batch', embeddings_freq=0, embeddings_metadata=None)\n",
    "\n",
    "reducelr = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, mode='auto', cooldown=0)\n",
    "progbar = tensorflow.keras.callbacks.ProgbarLogger(count_mode='samples')\n",
    "\n",
    "my_callbacks = [\n",
    "    earlystop,\n",
    "    modelcheckpoint,\n",
    "    tensorboard,\n",
    "    reducelr,\n",
    "    progbar,\n",
    "]\n",
    "\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         1049600     max_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         1049600     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          524800      dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            1026        dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,662,530\n",
      "Trainable params: 3,739,394\n",
      "Non-trainable params: 5,923,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-d026fba47162>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 68 steps, validate for 23 steps\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "1348/68 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 138s 102ms/sample - loss: 0.7448 - acc: 0.5861 - val_loss: 0.6853 - val_acc: 0.5996\n",
      "68/68 [==============================] - 138s 2s/step - loss: 0.8707 - acc: 0.5861 - val_loss: 0.6853 - val_acc: 0.5996\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "1348/68 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 140s 104ms/sample - loss: 0.5980 - acc: 0.6469 - val_loss: 0.6541 - val_acc: 0.6740\n",
      "68/68 [==============================] - 140s 2s/step - loss: 0.6942 - acc: 0.6469 - val_loss: 0.6541 - val_acc: 0.6740\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "1348/68 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 141s 104ms/sample - loss: 0.5374 - acc: 0.6773 - val_loss: 0.6923 - val_acc: 0.5427\n",
      "68/68 [==============================] - 141s 2s/step - loss: 0.6314 - acc: 0.6773 - val_loss: 0.6923 - val_acc: 0.5427\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "1348/68 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 137s 101ms/sample - loss: 0.5239 - acc: 0.6914 - val_loss: 0.6577 - val_acc: 0.6718\n",
      "68/68 [==============================] - 137s 2s/step - loss: 0.6040 - acc: 0.6914 - val_loss: 0.6577 - val_acc: 0.6718\n",
      "Epoch 5/50\n",
      "Epoch 5/50\n",
      "1348/68 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 137s 101ms/sample - loss: 0.7146 - acc: 0.7025 - val_loss: 0.7151 - val_acc: 0.3589\n",
      "68/68 [==============================] - 137s 2s/step - loss: 0.6009 - acc: 0.7025 - val_loss: 0.7151 - val_acc: 0.3589\n",
      "Epoch 6/50\n",
      "Epoch 6/50\n",
      "1348/68 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 141s 105ms/sample - loss: 0.5905 - acc: 0.6988 - val_loss: 0.6573 - val_acc: 0.6718\n",
      "68/68 [==============================] - 141s 2s/step - loss: 0.5758 - acc: 0.6988 - val_loss: 0.6573 - val_acc: 0.6718\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "history = feature_model.fit_generator(train_generator,\n",
    "                                    steps_per_epoch = ntrain // batch_size,\n",
    "                                    epochs = EPOCHS,\n",
    "                                    validation_data = val_generator,\n",
    "                                    verbose=1,\n",
    "                                    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "feature_model.save_weights('denenet121_forearm_fracture_detection_weights.h5')\n",
    "feature_model.save('denenet121_forearm_fracture_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = feature_model.to_json()\n",
    "with open(\"denenet121_forearm_fracture_detection_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation curves\n",
    "# get the details from history object\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/1-1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-15eb9f964eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/1-1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[1;32m    532\u001b[0m                                self.figure.dpi, metadata=metadata)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/1-1.png'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2deXgUVfa/38MmIiCroCCyiMoii0QUQUFRBBd2E3DfR0dlnFG/4jjqDDPOz8F9HxW3mRFIBFkUUFHcR9EgAoIiiziETQRk30LO74/TCU3I0km6U92d8z5PPemqunXrVHX6U7fOPfdcUVUcx3Gc5KVS0AY4juM4scWF3nEcJ8lxoXccx0lyXOgdx3GSHBd6x3GcJMeF3nEcJ8lxoXfyEJHKIrJNRJpFs2wiICJ/E5FXQp9bisi2SMqW8lyLReT00h7vOCXFhT6BCQlt7pIjIjvD1i8paX2quk9Va6rq/6JZtjSIyMki8rWIbBWR70Xk7CLKNhORbBE5poB9b4rIAyU5t6ouV9WapbG7gPP/R0T+nK/+41X1k2jUX8Q594pIo1idw0ksXOgTmJDQ1gyJ0v+AC8O2vZa/vIhUKX8rS80zwFSgNnAesKqwgqGHzUfAZeHbRaQhcC7wr9iZGV+ISC1gELAFuLicz51I/18VChf6JCbkYkgXkXEishW4VES6icgXIvKriKwRkSdEpGqofBURURFpHlr/T2j/jFDL+nMRaVHSsqH9/UTkBxHZLCJPishnInJlEeZnAz+psVxVvyvmcl8ln9ADw4FvVHVRyIanRCRLRLaIyFcicloh9+1YEdGw9ZYi8knout4B6oftqyQiE0RkbeiefigibUL7fgukAX8MvWVNCm3PEpFeoc/VQ/dtjYisEpFHRKRaaN/ZIrJCRP5PRNaLyGoRubyY+3ARsB74O3BFvuuqIiL3iMiy0D3IFJGjQvtOFJH3RGRj6Fr+L7T9gDeSXJvC1rNE5A4RWQDsCG37k4gsD92vhSLSP58dvwm9pW0VkW9FpKOI3CUi6fnKPSsiDxVzvU4EuNAnP4OAscDhQDomoL8DGgDdgb7Ab4o4/mLgHqAe9tbw15KWFZEjgAzgjtB5fwS6FmP3l8DDItKxmHK5TASOEpFTw7ZdxoGt+dlAh5B9E4DXReSQCOoeD3wRsv0BDn6gvAW0BhoD3wL/BlDVZ7B7/vfQW9agAuq+F0gJ2dUZ+07uCtvfFDgUOAq4AXhWRGoXYesV2Pc9Djgx3/27AxiKfed1gGuBXSJyOPAe8CZwJHAc8GER58jPMKAf9j8G8EPoOg4H7gfG5rqRRGQ48CfgEuxtbTCwEbtn5+deW+hhd1Fou1NWVNWXJFiAFcDZ+bb9DZhVzHG3A6+HPlcBFGgeWv8P8M+wsv2Bb0tR9mrgk7B9AqwBrizEpkuBTMxlkwV0CG3vB8wu4lpeAZ4JfT4B2A3UL6SsAFuBdmH36pXQ52Ptp6EALYE9QI2wYzNyyxZQb4PQfTks7L78OV+ZLKBX6PNPQJ+wfecDS0Ofzwa2AZXD9m8EUgo5dwsgB2gfWn8feDhs/zLg/AKOuwzILKTOA+wP2bQi37VcXsz/2Le55w3ZdFMh5WYCV4U+DwTmB/27SpbFW/TJz8rwFRE5QUSmhV7PtwCjMHEqjLVhn3cARXVSFlb2qHA71H7JWUXU8zvgCVWdDtwEvCsiHYDTsJZnYbwKpIVag5cD01R1Q+7OkAvkexHZDGwCDqPoa8+1fYOq7gjb9lNYnZVFZHTIVbEFWBraVVy9uRwZXl/oc5Ow9V9UdV/YelHfweXAAlX9NrT+GnCJiFQOrR+NiX1+jg6zuzTk/x+7UkTmhVxZv2IP3dz7UZgNYN/fpaHPl+Kt+ajhQp/85E9P+hzWwjpWVWtjrgOJsQ1rMBcEACIiHChm+amCuZhQ1SnAnZjAXwo8VsRxH2Kt9Asx10Ce20ZEzgT+AAzB3BZ1sdZycde+BqgvIoeGbQsPKb0ce/M4C3NVHJt7ytDf4tLDrgHCo4WaUUTHc2GE7unlwHGhh/haYDTQCOuQBhPkVgUcXth2gO1AjbD1xgWUOaA/A3gWuBF7m6oDfM/++1HUud4AuohIO+ztbWwh5ZwS4kJf8agFbAa2hzoNi/LPR4u3gJNE5EKxyIzfAQ2LKP868OdQB2ElTCj2YL7q6oUdFHpT+DfwMNZanxa2uxb28PgFqAr8OVSmSFR1GTA/ZE81ETkDc6+E17sb2IAJ4v35qliHuX8KYxxwr4g0EIsSugdzl5SUHlhrOQXoFFraY26m3E7ZMcDfRKSVGJ1EpB4W3dRMRG4OXWNtEcntQ/kG853XFZEjgRHF2FETE/712PPnWqxFn8sY4P9EpHPIhtYicjRA6K1pUuiefKaqJX7gOQXjQl/xuA374W/FWvfpRRcvO6q6Dos+eQQTxFbAXEwgC+IfWGt8KuaTfgzrOBwHTCumM/JVrIU8TlX3hm2fjr0VLMH6M7ZgrelIGIZ1Lm4E7uZAl8LLwOrQshD4b75jxwAdRWSTiEwooO6/APOABdgDZTbw/yK0K5wrgEmqulBV1+YuwOPAABGpAzwITMb85FuA54HqqroZOAd72/kZ60ztGar3FeA7zKX0NtYxXSiqOh94AutMX4OJ/Oyw/eOw7zc9ZMMb2NtVLq8CJ+Jum6gioY4Pxyk3Qj7j1cBQjeHAISfxCLl+5gONVbXQ0clOyfAWvVMuiEhfETk8FM54D+ZG+TJgs5w4IuSm+wMw1kU+uvhINqe86IFFgVTDXBwDVbUw141TwQjF8q/C3GrnFl3aKSnuunEcx0ly3HXjOI6T5MSd66ZBgwbavHnzoM1wHMdJKObMmfOLqhYYthx3Qt+8eXMyMzODNsNxHCehEJGfCtvnrhvHcZwkx4XecRwnyXGhdxzHSXJc6B3HcZIcF3rHcZwkx4XecRwnyXGhdxzHSXIiiqMXkb5YutPKwBhVfSDf/keBM0OrNYAjQhMOICJXYHNEAvxNVV+NhuGO4yQPu3bB6tW2rFply9atUL06HHpoyZbq1aFy5eLPWZEoVuhDKWWfxvJVZwFfichUVV2UW0ZVfx9W/hZskmNCkxrch02GoMCc0LGbonoVjuPEJaqwYcN+8S5s2bCh+LpKQtWqJX9AlGWpVg0k1vO0lYFIWvRdscmKlwOIyHhgALCokPLDMXEHy0I3U1U3ho6dic1AP64sRjuOEzy5rfCiBHz1atiz5+BjjzgCmjSBZs2gWzf7nH+pXdvOsXNn0UskZcKXbdtg/fqC9+XklO5eiET2plFcmSZN4Pzziz9fSYlE6Jtw4OS/WcApBRUUkWOwmehnFXHsQXOFisj1wPUAzZo1y7/bcZxyRBV++aVg0S6uFZ4rVk2awGmnHSzeRx0FRx5pLeBIOOwwW8oDVdi7N7KHRUkfLoU9WHbnS9R96qnBCX1BLySF5TYeBkwIm7U+omNV9XlsWjNSUlI8b7LjxIhduwoX7qJa4SL7W+HHHLNfxI866kAhr1Mnvl0YRSFiD6Bq1eDww8vnnDk5Bz40YnXvIhH6LGzS4VyaYtPAFcQw4KZ8x/bKd+yHkZvnOE4kFNYKz79s3HjwsTVq7BftglrhTZpYK7xq1fK/rmSnUiW7/zVqxPY8kQj9V0BrEWmBzQAzDLg4fyEROR6b5PfzsM3vAH8XkdzJf/sAd5XJYsepYOzZAytXFi3ga9YU3Qpv3hy6dy9YxA8/PHFb4U5kFCv0qpotIjdjol0ZeElVF4rIKCBTVaeGig4HxmvYlFWqulFE/oo9LABG5XbMOo5j5EamLF++f1m2bP/nrKyDOwlzW+FNmkCPHgULeOPG3gp3jLibSjAlJUU9H72TbOzZAz/9dKCAhy9btx5YvlEjaNkSWrWyv82beyvcKRoRmaOqKQXti7uJRxwnEcn1kRck4suXm+slvE11yCEm4C1bwhln7P/csiW0aFF+kSZOxcCF3nEiZPdua5UXJub5W+WNGxcs5K1a2b5KnoDEKSdc6B0nREGt8vy+8vBWefXq1vpu1Qp69jxQzJs391a5Ez+40DsVit27YcWKwlvl27YdWP7II024e/U6UMhbtvRWuZM4uNA7SYWqjUIsTMgLapXnCne4mLdqZa3yWMc3O0554ELvJByFtcpz3Szbtx9YPrxVnhvFEt4q9+gVJ9lxoXfinpwc+OYbmDEDpk+HL744MK780EP3C/dZZx3sK/dWuVPRcaFPdLKzoUryfY2//gozZ5q4z5gBa9fa9pQUuPNOaNNmv4ulUSNvlTtOUSSfQlQU9u6Fv/wFHnoIXngBLrssaIvKhCrMn7+/1f7f/8K+fVC3LvTpA+edB+eea6LuOEmJasxaLC70icjixXDppZCZaZmorrvOmrgpBQ6Ki1u2bIH33jNhf/tty9kC0LkzjBwJ/frBKack5QtLyXjrLcjIgJde8puRzNx4o/0oxo6NetX+X5NIqMI//wm33WaO6QkTLIA7JQUGDTLhj+MmryosXLi/1f7pp+Z5OvxwOOcca7X37Wudp06IuXMhNdVy2F52md0oJ/nYswfS0+HCC2NSvQt9orBuHVxzDUybZj/2V16x1jzA5MmWX3boUHj//chndSgHtm0zk3LFfWVoGpoOHeD2263V3q2bJ98qkHXrYMAAaNAANm2yVr0LfXIyc6Z1TKWlxaZ+VY2rpUuXLurkY+pU1YYNVQ85RPXxx1X37Tu4zLhxqqB6443lb18YOTmqixapPvywau/eqtWqmVm1aqkOGqT6wguqK1cGamJisGuX6mmnqR56qOrXX6tecolqvXqqe/YEbZkTCy67TLVOHdXdu0tdBZZNuEBd9RZ9PLN9u7lpnnsOOnaEDz6Adu0KLjtsmL3mjx5tTu7rritXMz/4YH+rfcUK296uHfzud9Zq7949rl404htV+O1vrUc6I8O+z9RUeO0169To1y9oC51osmsXTJkCQ4bE7kdS2BMgqMVb9CG+/FK1dWtVEdX/+z9r4RVHdrbqueeqVq2q+tlnMTXvhx9UH3tMtU8fe9EA1cMOU+3fX/Wf/1T96aeYnj65efxxu6H33LN/265dqocfrnrllcHZ5cSGyZPt+3777TJVQxEt+sCFPf9S4YV+717Vv/5VtXJl1aOPVv3gg5Idv3GjaqtWqo0bq2ZlRc2sHTtUp09XveUWq96anaonnKD6hz+ozpwZ2bPIKYZ331WtVEl14MCDXXRXXGFi7zc6ubj4YtX69cvslnOhTxSWLTO/LKgOH666aVPp6vn2W9WaNVW7dlXdubPU5ixdqvrkk6r9+qlWr25mHXqo6vnnqz79tOry5aWu2imIJUtU69ZVPfFE1a1bD94/bZp9CW++Wf62ObFhxw77rV53XZmrKkro3UcfD6jCq6/CLbdA5crmi734oGl5I6ddO/jXv2DwYIvNfemliAZi7NoFH3+839f+ww+2vXVruP56C3/s2dMSgTlRZssW6N/f0mFOmQI1ax5c5uyzbQRZejpccEH52+hEnxkzLDQtNTWmp3GhD5oNG0xF33jDVPTVV+GYY8pe76BBcO+9MGoUnHSSPUQKYMWK/cI+axbs2GFC3qsX3Hyz9fsde2zZzXGKYN8+e7AvWWJhdi1aFFyuWjX7Xl9/3Z7K/sRNfNLToWFD+8HFksKa+uEL0BdYDCwFRhZSJhVYBCwExoZt3wd8E1qmFneuCuW6eecd1SOPtM7Tf/zDOlOjyb591jtauXKer3/3btX33lO97TbVNm32+9pbtlS9+WbzDmzfHl0znGIYOdK+hGeeKb7sO+9Y2UmTYm+XE1u2bVOtUUP1hhuiUh1l8dEDlYFlQEugGjAPaJuvTGtgLlA3tH5E2L5txZ0jfKkQQr9jh+qIEXb727ZVnTs3dufavFn3HHuC7qjZQK89Z4XWrGmnrVZN9ZxzVB99VPX77y3+3QmA116zLyTSH/vevdZxN2xYbO1yYk96un33JQ24KISihD4S101XYKmqLgcQkfHAgFDrPZfrgKdVdVPoLeHnkr5ZVBi++QYuuQQWLYIRI+CBByydQRTZuxc++yzXJVOb3Uun8BUn87uPBlHj8k85u38NzjrLp7oLnK++stHOPXvC449HdkyVKhZv/dpr5mfzHMyJS3q6TYhw+ukxP1UkE6E1AVaGrWeFtoVzHHCciHwmIl+ISN+wfdVFJDO0fWBBJxCR60NlMtevX1+iC0gYcnLgwQeha1fYuNGyeD3+eNREfvVqePFF04AGDeDMM+HRR+GII+A3Dx3H5mfH0W7vNzy+/VouvEBd5INmzRoYONB+6K+/XrKBMmlpNkpt+vTY2efElq1b7fsbOtQCMGJMJC36gsI1NN96Fcx90wtoCnwiIu1V9VegmaquFpGWwCwRWaCqyw6oTPV54HmAlJSU/HUnPitXwuWXw4cfWmfa88+bGpeRn3+GJ56w5Ibz5tm2pk1tkGy/ftC7N9SqlVv6PNh0P/zxj9Y5e/vtZT6/U0p27bL/g82bbfRrw4YlO/6MM+wJnpFhQuEkHm++af8Hscptk49IhD4LODpsvSmwuoAyX6jqXuBHEVmMCf9XqroaQFWXi8iHQGfM518xGD8ebrjBIiteegmuvLLMOaf37IEnn7SAmu3boUcP+Mc/TNzbty+i+pEj4euvbeaOE0+0BO9O+aIKv/kNzJ4NEydadreSUqWKCfzLL1toXkGhmE58k54OTZpYMsLyoDDnve7vTK0CLAdasL8ztl2+Mn2BV0OfG2CunvpAXeCQsO1LyNeRm39Jms7YTZssERWodutmo4/KSE6OjZVp3dqqPe881e++K2ElW7fagJw6dWyAjlO+PPywfXl/+UvZ6vnwQ6tn3Ljo2OWUH7/+atEQt94a1Wop68hY4DzgB6wlfndo2yigf+izAI9gHbQLgGGh7aeF1ueF/l5T3LmSQug/+MDSF1SurDpqlEVKlJGFCy2vTG7agenTy1DZsmWWCbFdu4JHYDqxYcYMS28wdGjBGUhLQna2heYOGhQd25zy49VX7Yf83/9GtdoyC315Lgkt9Lt2WQIyEdVjj1WdPbvMVW7YYPHtlStbI/yxx6KUqXbmTBOdwYPLLjpO8Xz/veWp6djR4qejwYgRllFu8+bo1OeUD+efr9qsWdRjmosS+kiibpxIWLQITj3V0gRfd52lDO7atdTV7d1rfvhjj4VnnjG37pIllvY3KpN0nH22zTf7xhvw979HoUKnUH791dIbVKtm6Q2iFfKUmgq7d1vHnpMYbNoE775r3105zmjvQl9WVE2Ru3SBrCz7IT/3XJk6yN55x9LPjxhhATLz5sHTT0clUOdAbr3V5p69914Xi1ixb5+FQf34oz1Uo5HeIpdu3SzMKj09enU6sWXyZGvFxTi3TX5c6MvCmjUW6jJiBJx1FixYYC23UvLDDzZlZN++FlkzebKlPmnfPoo2hyNioZ4nnWSDuL7/PkYnqsDceac9uZ9+2sKjokmlSnDRRTYm49dfo1u3ExvS0y2XUUpKuZ7Whb60TJpkIYoffwzPPmvB7I0bl6qqX3+1iaTat4ePPjLvz8KFNl1ozN/uDj3UrqV6dTvh5s0xPmEF4l//gocftuxwsZrxKy3NWohTpsSmfid6/PKLzRBWzm4bwDtjS8yWLapXX2392F26WCdbKcnOttmYGjSw/ttrr1VduzaKtpaEjz5SrVLFOoqinVytIvL55xZCd9ZZsZ3nNSdH9ZhjbNIAJ755/nnTja+/jkn1eGdslPj8c+jUCV55Be6+20Y1Hn98qar68ENz699wA7RtC3PmwAsvQKNGUbU4cs44w1IyTJsG990XkBFJwqpVNvK1aVMbvRqV3vNCELEW4syZllrDiV/S021yh06dyv3ULvSRsHeviV+PHpaz5qOP4G9/K9VEvsuXWz6aM880l83rr5vod+4cfbNLzI03wrXXwv33w4QJQVuTmOzcaTlstm2DqVOhfv3YnzMtDbKzzQXnxCc//wwffBCM2wbcdVMsP/xgU/KB6uWX26i2UrBli6Udr1bNJtH+298sW3HcsWuX6qmnmpHz5wdtTWKRk2Pzf4qoTp1avudt2dJG1DnxyTPPmIbE8DeFu25Kgar5Ujp1sgD2jAyb/enww0tUTU6OpSQ57jjLSDxsmEXX3H131LMTR4dDDrEcLLVrW+esuwMiZ/RoGDvW3vYuvLD8zitirfr334dkzf6a6GRkwAknxDCErmhc6Ati/Xp7/b7+eks6tGCBhbGVkM8+szFTV18NzZtbHqtXX4Wjjoq+yVHlqKMs5nvVKnsyZWcHbVH889ZbcNddJrh33VX+509NtZj9N94o/3M7RbNmjbl709KCcdvgQn8w06db2OQ771hC93fesSxzJeB//4Phw82lv3Yt/Oc/1m9bhoGy5c+pp1rY6MyZlvXSKZxFi2zO186dI56IPep07GivjRkZ5X9up2gmTDAPQTkPkgrHhT6XHTvgppvg/PMt1/dXX9nI0UqR36Lt263P9oQTbLDTvffC4sU2FimgB3nZuPpquycPP2wzGjkHs3Gjubhq1LAvPagZn3LdNx9+COvWBWODUzAZGeayads2OBsKc94HtQTSGZuZqXr88dZZctttqjt3lujwnBzV//xHtUkTq2LYMNWffoqRreXNnj2qZ5yhWr266pw5QVsTX+zdq3r22dbDHuVMhKViwQL7B3z66aAtcXJZudK+k7/+NeanwjtjC2HfPvh//8/cFNu22ai1hx6yUaIR8tVX0L27pYxp3Bg++QTGjYNmzWJod3lStarFgDZsaP0WP/t0wHncfrv9z/zzn5Z3JmhyW42e+yZ+yA1TDtBtAxXZdbNiBfTqZVPrDR4M8+fb3HsRsno1XHGF+d1//NFcs19+Gf10JnHBEUdYjPb69dYpvXdv0BYFz4sv2gCz3/8erroqaGv2k5pqrY3V+SeBcwIhPd0i9447LlAzKp7Qq8K//21TuM2fb5/Hj4d69SI6fOdOG0903HF22MiRFi551VUlcucnHl26wJgxltvn978P2ppg+ewzG1x2zjkWUhlPpKXZ/7gPeAuen36CL74IvDUPVDAf/YYNqqmp5jM7/XTVH3+M+NCcHNWMDEsrAjZfx7JlMbM0frntNrsBY8YEbUkw/PST6hFH2MQyGzcGbU3BdOigetppQVvhPPig/VbKSShwHz02mKRDB4sz/n//z4YjN28e0aFz55qXJzXVxkvNmmVjilq2jKnF8ckDD1hL9re/tdZKRWL7douw2bXL0hvUrRu0RQWTmmrxvCtXBm1JxSY93dIRx4FQJL/Q79plOYDPPhtq1bJRSyNHQuXKxR66bp1ll+3SxUKl//lP+Ppry1NTYalSxXxWTZta30ZF8QWrmn9u3jzrbW/TJmiLCifXVfD668HaUZFZvhwyM+PDbUOyC/2CBdZb+sgjFg8+Z45NslEMu3fDgw9aorlXXjGX9JIlNp1fBM+H5KdePYsZ37LFMrTt3h20RbHn73834fzHP+C884K2pmhat7bBWz54Kjhy732cCH1EfnOgL7AYWAqMLKRMKrAIWAiMDdt+BbAktFxR3Lmi4qPft0/1kUcsvrlRI9Vp0yI6LCdHdfJk1VatzLV2wQWqixeX3ZykZcIEu1HXXBP1iY7jismT7TovvTRxrvOBB8zmEvRDOVGkc2fVU04p11NShI8+EpGvDCwDWgLVgHlA23xlWgNzgbqh9SNCf+sBy0N/64Y+1y3qfGUW+pUrVXv3tksbMED1558jOmzBAhv7Aqpt2qi+/XbZzKgw3H13cg/SmT9ftWZN1ZNPjtN0o4WwbJl9L//4R9CWVDx++MHu/SOPlOtpixL6SFw3XYGlqrpcVfcA44EB+cpcBzytqptCbwm5o2rOBWaq6sbQvpmht4PYkJFheWq++MJCASdNsoE+RfDLL+bV6djRPDtPPGFu2HPPjZmVycWoUZY24ne/s9DLZOKXX6zztVYt+1+Ky3SjhdCyJZx8srtvgiB3wNrQocHaEUYkQt8ECO++zwptC+c44DgR+UxEvhCRviU4FhG5XkQyRSRzfWnTrC5ebJkWjz8evvkGrrmmyAQze/faeJfWreG55yyIZMkSuOWW2E4IlHRUqmR5cFq1sn/sZIn02LvXBoetXm0iX8LEdnFBWpq1XpYuDdqSikVGhg2XP/rooC3JIxKhL0gtNd96Fcx90wsYDowRkToRHouqPq+qKaqa0rCYFnihHH88vPuujQo89tgii86YYZGWt95qjZ558+DJJ8tnMqCk5PDDrXN21y5Lk7BzZ9AWlZ1bb7UEYS+8AKecErQ1pSM3tbZH35Qf331nQSBpaUFbcgCRCH0WEP5oagrkj6nLAqao6l5V/RHruG0d4bHR4+yzi2yOf/+9BUycd56luZk61bIQt2sXM4sqDiecYC37uXMtj78e9DxPHJ57Dp55Bu64Ay67LGhrSk+zZpaDx3PflB8ZGeZJGDIkaEsOpDDnve7vaK2CdaK2YH9nbLt8ZfoCr4Y+N8DcNfWxTtgfsY7YuqHP9Yo6XyxGxm7cqHrrrapVqqjWrq360EOqu3dH/TSOqmXpC6AjKmp89JH9o/Trp5qdHbQ1ZefRR+37+P77oC1JfnJyLJKjZ89ATk9Zom7seM4DfsCib+4ObRsF9A99FuARLLxyATAs7NirsbDMpcBVxZ0rmkK/d69N1Vi/vk3jef31quvWRa16pyD27bP8EJUqqc6cGbQ1JePHH1UbNLCU1aWcGzjuyMqyf/5Ro4K2JPmZPz/QCLSihF40zl6xU1JSNDMzs8z1vP++uVm//dbSFzz2mEXWOOXA1q3mMlizxvI4x8EQ8GLZts060H76ydKQBpxtMKqccYZNkPLtt0Fbktzcc48NrFu9Gho1KvfTi8gcVU0paF/SjYxduhQGDTJ3/bZtlsRv1iwX+XKlVi2YMsVmRh840L6IeCYnBy6/3IQwPT25RB5sdObChbY4sUHV/nfOPDMQkS+OpBH6rVvhzjutY3XmTHuwfved9Ykk5DR+iU6rVpYTZ+FCyxETZ2+OBzBqlIVQPvRQcg6gGDrUfgQeUx875s2z+Ox4SXmQj6QS+meftTmalyyBu+4q0ZhIsAEAACAASURBVERRTiw491zLdjlhgv2NRyZMgL/8Ba680nx9yUjjxtCzpwl9PD9wE5n0dEuENXhw0JYUSNII/VFHwbJl8PLLcOSRQVvj5HH77TB8ONx9N0ybFrQ1B/LNNzZNWLdulpo0mV/90tIsvnjBgqAtST5U7SHauzc0aBC0NQWSNEIPxWY7cIJAxNJRdOpkr1uLFwdtkfHzz5beoF49m6PgkEOCtii2DBlio5g9pj76zJljaYnjbJBUOEkl9E6cUqOG+cCrVbPO2S1bgrVnzx7zW//8s43obdw4WHvKg4YN4ayz3H0TC9LTbZ6GgQODtqRQXOid8uGYY2wo/pIlcOmlFukSBKpw882WKuOll2xWmYpCWpqFpc2dG7QlyUOu26ZPn4jnnQ4CF3qn/OjVCx59FN580zpAg+CZZyx/zV13Wd9BRWLQIGt5evRN9Jg9G/73v7h224ALvVPe3HyzhVvmhjSWJ7NmWTrlCy+Ev/2tfM8dD9SvbwNM0tPdfRMtMjLMJTkgf+b2+MKF3ilfRKxV3bWrDVIqr0E8y5ZZNsfjj4f//Mc6JisiqamwYoWNWHbKRk6OCX3fvpbBNY6poP/tTqBUr26RLjVrWkto06bYnm/LFujf31qxU6dC7dqxPV88M3CgZXh1903Z+e9/YdWquB0kFY4LvRMMTZrAxInm3xw+3PJGx4KcHOv8XbzYOoNbtYrNeRKFunVtIFtGRnAd4slCRoY1Wvr3D9qSYnGhd4LjtNPg6adtUoA//jE257j3Xuv8ffRRG9DiWAt05UrrSHRKx7591nA47zzL7RTnuNA7wXLddXDDDTB6tOXGiSbp6XD//XDttdYJ7BgDBtgAMR88VXo+/RTWrk0Itw240DvxwOOPQ48ecPXV0YvxnjPHont69LC3hmROb1BSate2DsTXX3f3TWlJT7fJ4i+4IGhLIsKF3gmeatUsuVi9etZZWNoJ4nNZu9bqadDA+gGqVYuOnclEWprlTf/ss6AtSTyys+3/6oIL4LDDgrYmIlzonfigUSNLR7BunYnQ3r2lq2f3bssguHGjRdgccUR07UwWLrzQOhLdfVNyPvrI0mfE+SCpcFzonfghJQWefx4++MCyXpYUVfP3f/45vPKKJVJzCqZmTTj/fHuTilXEU7KSnm4t+X79grYkYlzonfji8sstL/wTT5hYl4THH7dj7r3XBkc5RZOWZm9QH38ctCWJw969Ngakf39L1pcguNA78ceDD1qmxRtusPlbI+Hdd+G22yyfy333xda+ZOG880ysfPBU5MyaBRs2JJTbBiIUehHpKyKLRWSpiIwsYP+VIrJeRL4JLdeG7dsXtn1qNI13kpQqVez1+Mgjzd++dm3R5ZcssR9eu3bwr39V3PQGJeWww8xXP3GidTA6xZORYVFLCTblZLG/CBGpDDwN9APaAsNFpG0BRdNVtVNoGRO2fWfY9vgfQubEBw0aWOfspk02acaePQWX27zZXqMrV7YJyWvWLF87E53UVIty+uCDoC2Jf/bsMbfNgAEJN09pJE2frsBSVV2uqnuA8UB8p2pzkoOOHW1uyP/+F0aMOHj/vn02a9XSpdap2KJF+duY6PTrZw9Hd98Uz8yZ8OuvCTNIKpxIhL4JsDJsPSu0LT9DRGS+iEwQkaPDtlcXkUwR+UJECpyCRUSuD5XJXF/WGGonuUhNhZEj4bnnbAnnj3+E6dPhySct171Tcg491Fqob7xR+pDWikJGBtSpY5OMJBiRCH1BQwrzJ7N+E2iuqh2A94BXw/Y1U9UU4GLgMRE5KKuUqj6vqimqmtLQJ3518vO3v1nL85ZbbOg5WKrh0aPhxhut09YpPampNu7g/feDtiR+2bXLXImDBiXkALxIhD4LCG+hNwVWhxdQ1Q2quju0+gLQJWzf6tDf5cCHQOcy2OtURCpXhrFjoXlzm+v1jTcsf03PnhZS6ZSNc8+1DkYfPFU4775r6a4T0G0DkQn9V0BrEWkhItWAYcAB0TMicmTYan/gu9D2uiJySOhzA6A7sCgahjsVjDp1rEW1fbt1zh55pOVqqVo1aMsSn0MOsZQRkybZyGLnYNLTLUVHgmZALVboVTUbuBl4BxPwDFVdKCKjRCQ3imaEiCwUkXnACODK0PY2QGZo+wfAA6rqQu+UjrZtrWV/4okWYeNuvuiRlmYRTDNnBm1J/LFzp6XTGDw4YRsWonE2d2RKSopmZmYGbYbjVCz27IHGjS0twr//HbQ18cUbb9hb5MyZNudunCIic0L9oQfhI0scx7EOxkGD7E1p166grYkv0tPt7TGBI7tc6B3HMdLSYOtWePvtoC2JH7Zvh7feshZ9lSpBW1NqXOgdxzHOPBPq1/fBU+FMmwY7diRcbpv8uNA7jmNUrWot16lTTdwce+g1bgynnx60JWXChd5xnP2kppq7Yvr0oC0Jnq1brUU/dKiN5UhgXOgdx9lPz542K5e7b8w3v2tXwg6SCseF3nGc/VSpYi3Yt96CbduCtiZY0tPhqKOge/egLSkzLvSO4xxIaqoNEpo2LWhLgmPzZpgxw2YqS4L5DRL/ChzHiS49eliKiYqc+2bqVBtEluDRNrm40DuOcyCVK5v7Zvp0S+RVEUlPh2bN4NRTg7YkKrjQO45zMGlpluDszTeDtqT82bTJslVedBFIQVnaEw8XesdxDqZbN2jatGK6byZPtklYksRtAy70juMURKVK1qJ95x2bPq8ikZ5u01KmFJgfLCFxoXccp2DS0qxDcsqUoC0pPzZsgPfes8ijJHHbgAu94ziF0bUrHHNMxRo89cYbNul8ErltwIXecZzCELGW7bvv2pyyFYGMDDj2WOjUKWhLoooLveM4hZOaCtnZNs1gsvPzzzBrlrXmk8htAy70juMURZcu0LJlxXDfvPEG5OQkRW6b/LjQO45TOCLWwn3/fVi/PmhrYkt6Opxwgs1JnGS40DuOUzSpqdZBmczumzVr4KOPki7aJpeIhF5E+orIYhFZKiIjC9h/pYisF5FvQsu1YfuuEJEloeWKaBrvOE450LEjHHdccg+emjgRVJMu2iaXYoVeRCoDTwP9gLbAcBFpW0DRdFXtFFrGhI6tB9wHnAJ0Be4TkbpRs95xnNiTG33z4Yewbl3Q1sSG9HRo3x7aFiRtiU8kLfquwFJVXa6qe4DxwIAI6z8XmKmqG1V1EzAT6Fs6Ux3HCYy0NOuonDgxaEuiz6pV8OmnSdkJm0skQt8EWBm2nhXalp8hIjJfRCaIyNElOVZErheRTBHJXJ/sHT6Ok4jktnaT0X3z+uv2t4ILfUE9E5pv/U2guap2AN4DXi3Bsajq86qaoqopDRs2jMAkx3HKndRU+OQTWL06aEuiS3q69UMcf3zQlsSMSIQ+Czg6bL0pcMA3raobVHV3aPUFoEukxzqOkyCkplqH5YQJQVsSPX76Cb74Imk7YXOJROi/AlqLSAsRqQYMA6aGFxCRI8NW+wPfhT6/A/QRkbqhTtg+oW2O4yQabdpYjHkyDZ6qAG4biEDoVTUbuBkT6O+ADFVdKCKjRKR/qNgIEVkoIvOAEcCVoWM3An/FHhZfAaNC2xzHSUTS0uCzz2DlyuLLJgIZGTb6t1WroC2JKaJ6kMs8UFJSUjQzMzNoMxzHKYglSyym/uGH4Q9/CNqasrF8uQn86NFwxx1BW1NmRGSOqhaYRN9HxjqOEzmtW0Pnzsnhvsl121x0UbB2lAMu9I7jlIy0NJg9G1asCNqSspGeDqecAs2bB21JzHGhdxynZOS2gHNbxInIkiUwd27Sd8Lm4kLvOE7JaNkSTj45sQdP5bqeKoDbBlzoHccpDampMGcOLF0atCWlIz0duneHo48uvmwS4ELvOE7JyXV5JKL75rvvYMGCCuO2ARd6x3FKQ7Nm0K1bYrpvMjIsI+fQoUFbUm640DuOUzpSU2HePFi8OGhLIkfVHk6nnw5HHRW0NeWGC73jOKUjtyMzkWLqFy40102S57bJjwu94zilo0kT6NEjsdw36elQqRIMGRK0JeWKC73jOKUnLc1ayQsXBm1J8aja20evXtCoUdDWlCsu9I7jlJ6hQ61jMxHcN/PmwQ8/VDi3DbjQO45TFho3hp49TejjLEHiQWRkQOXKMHhw0JaUOy70juOUjbQ0+P57i02PV3KjbXr3hgYNgram3HGhdxynbAwebB2c8ey+mTPH0hJXoEFS4bjQO45TNo44As46y1rM8eq+yciAKlVg0KCgLQkEF3rHccpOaqrlvZk7N2hLDiY32qZPH6hXL2hrAsGF3nGcsjN4sLWY49F98+WXNgl4BXXbgAu94zjRoH59OPvs+HTfpKdDtWowYEDQlgRGREIvIn1FZLGILBWRkUWUGyoiKiIpofXmIrJTRL4JLf+MluGO48QZqak261Q8zfmck2NvGeeeC3XqBG1NYBQr9CJSGXga6Ae0BYaLSNsCytUCRgCz8+1apqqdQssNUbDZcZx4ZOBAqFo1vlIifP45rFpVIQdJhRNJi74rsFRVl6vqHmA8UNA70F+B0cCuKNrnOE6iULeudXhmZFhLOh5IT4dDDoH+/YO2JFAiEfomwMqw9azQtjxEpDNwtKq+VcDxLURkroh8JCKnF3QCEbleRDJFJHP9+vWR2u44TryRlgYrV9rk4UGzbx9MmADnnQe1agVtTaBEIvRSwLa83hYRqQQ8CtxWQLk1QDNV7Qz8ARgrIrUPqkz1eVVNUdWUhg0bRma54zjxx4AB1oKOB/fNp5/CmjUV3m0DkQl9FhA+sWJTYHXYei2gPfChiKwATgWmikiKqu5W1Q0AqjoHWAYcFw3DHceJQ2rXhr59bYrBoN03GRlw6KFw/vnB2hEHRCL0XwGtRaSFiFQDhgFTc3eq6mZVbaCqzVW1OfAF0F9VM0WkYagzFxFpCbQGlkf9KhzHiR/S0mD1avjss+BsyM42t80FF0DNmsHZEScUK/Sqmg3cDLwDfAdkqOpCERklIsX1cJwBzBeRecAE4AZV3VhWox3HiWMuuACqVw928NRHH8HPP1foQVLhiMbZ4IaUlBTNjKc4XMdxSs7Qodaiz8qy1MDlzW9+A6+9ZmJfo0b5nz8ARGSOqqYUtM9HxjqOE31SU2HtWvj44/I/9969MHGihVRWEJEvDhd6x3Giz/nnm8gG4b754APYsMHdNmG40DuOE30OOwwuvNBa1tnZ5Xvu9HSLm+/bt3zPG8e40DuOExtSU2H9evjww/I755498MYbFs9fvXr5nTfOcaF3HCc29OtnoY3lOXjqvffg1199kFQ+XOgdx4kNhx5qHaJvvGEdpOVBejocfrjl3HHycKF3HCd2pKXBxo3w/vuxP9fu3TB5sk0XWK1a7M+XQLjQO44TO84919IilIf75p13YMsWd9sUgAu94zix45BDLE/9pEnWURpLMjJsTtjevWN7ngTEhd5xnNiSlgabN8O778buHDt3wpQpNndt1aqxO0+C4kLvOE5sOftsm5QkloOnZsyAbdt8kFQhuNA7jhNbqlWzDtLJk2FXjCagy8iAhg3hzDNjU3+C40LvOE7sSU2FrVvh7bejX/f27fDmmzBkCFSpEv36kwAXesdxYs9ZZ0H9+rFx30yfDjt2uNumCFzoHceJPVWrWot76lQT5WiSng6NGsEZZ0S33iTChd5xnPIhNdXcLDNmRK/Obdtg2jTLfx9E3vsEwYXecZzyoWdPOOKI6A6eevNN6+D1QVJF4kLvOE75UKWKuW/eesta4tEgPR2OOgq6d49OfUmKC73jOOVHWpoNbpo2rex1bdlibqCLLoJKLmVFkRCxSHv37iUrK4tdsYrBdRKW6tWr07RpU6r6aMjEoEcPOPJIa4mX1d0yZYqlVXC3TbFEJPQi0hd4HKgMjFHVBwopNxR4HThZVTND2+4CrgH2ASNU9Z2SGpmVlUWtWrVo3rw5IlLSw50kRVXZsGEDWVlZtGjRImhznEioXNk6Tp9/3uLqa9UqfV0ZGXD00XDKKdGzL0kp9n1HRCoDTwP9gLbAcBFpW0C5WsAIYHbYtrbAMKAd0Bd4JlRfidi1axf169d3kXcOQESoX7++v+klGmlpllJ46tTS17Fpk2WrTE11t00ERHKHugJLVXW5qu4BxgMDCij3V2A0EP6rGwCMV9XdqvojsDRUX4lxkXcKwv8vEpBu3aBJk7INnpo82SYz8UFSERGJ0DcBVoatZ4W25SEinYGjVfWtkh4bOv56EckUkcz169dHZLjjOAlKpUom0G+/bdP+lYaMDGjRAk4+Obq2JSmRCH1BTSbN2ylSCXgUuK2kx+ZtUH1eVVNUNaVhw4YRmFS+bNiwgU6dOtGpUycaN25MkyZN8tb3RJhj+6qrrmLx4sVFlnn66ad57bXXomEyAOvWraNKlSq8+OKLUavTcaJCWpp1pE6ZUvJjN2ywuWFTU8Hf6CIiks7YLODosPWmwOqw9VpAe+DD0Gt0Y2CqiPSP4NiEoH79+nzzzTcA/PnPf6ZmzZrcfvvtB5RRVVSVSoX4C19++eViz3PTTTeV3dgw0tPT6datG+PGjeOaa66Jat3hZGdnU8WTSTkloWtXOOYYa5lfcUXJjp00CbKz3W1TAiL5dX4FtBaRFsAqrHP14tydqroZaJC7LiIfAreraqaI7ATGisgjwFFAa+DLshh8660Q0tyo0akTPPZYyY9bunQpAwcOpEePHsyePZu33nqLv/zlL3z99dfs3LmTtLQ07r33XgB69OjBU089Rfv27WnQoAE33HADM2bMoEaNGkyZMoUjjjiCP/3pTzRo0IBbb72VHj160KNHD2bNmsXmzZt5+eWXOe2009i+fTuXX345S5cupW3btixZsoQxY8bQqVOng+wbN24cTz31FBdddBFr166lcePGAEybNo177rmHffv20ahRI9599122bt3KzTffzNdff42IMGrUKC644AIaNGjAr6HX6/Hjx/Pee+8xZswYLr30Uho1asTXX3/NySefzODBg/n973/Prl27qFGjBq+88gqtW7cmOzubO+64g5kzZ1KpUiVuuOEGWrVqxZgxY3j99dcBmDFjBi+//DIZscxX7sQXIibUjz5qc8rWqxf5senpcOyx0Llz7OxLMop13ahqNnAz8A7wHZChqgtFZFSo1V7UsQuBDGAR8DZwk6ruK7vZ8cOiRYu45pprmDt3Lk2aNOGBBx4gMzOTefPmMXPmTBYtWnTQMZs3b6Znz57MmzePbt268dJLLxVYt6ry5Zdf8uCDDzJq1CgAnnzySRo3bsy8efMYOXIkc+fOLfDYFStWsGnTJrp06cLQoUPzRHTt2rXceOONTJo0iXnz5jF+/HjA3lQaNmzIggULmDdvHj179iz22pctW8b777/P6NGjadOmDZ9++ilz587lnnvu4U9/+hMAzz77LKtXr2bevHnMnz+fYcOGcc455zB//nw2bNgA2NvOVVddVez5nCQjNdVa5pMnR37M+vUwa5a7bUpIRO/bqjodmJ5v272FlO2Vb/1+4P5S2ncQpWl5x5JWrVpxcliH0Lhx43jxxRfJzs5m9erVLFq0iLZtD4xGPfTQQ+nXrx8AXbp04ZNPPimw7sGDB+eVWbFiBQCffvopd955JwAdO3akXbt2BR47btw40kIDSYYNG8ZNN93EiBEj+PzzzznzzDM55phjAKgXakm99957TA794ESEunXrkp2dXeS1X3TRRXmuql9//ZXLL7+cZcuWHVDmvffe49Zbb6VyKOFU7vkuvvhixo4dyyWXXMKcOXMYN25ckedykpAuXaBlS2uhX311ZMdMnAg5OT5IqoS4Y7WMHHbYYXmflyxZwuOPP86XX35JnTp1uPTSSwuM8a5WrVre58qVKxcqqIcccshBZVQP6ssukHHjxrFhwwZeffVVAFavXs2PP/6IqhYYkljQ9kqVKh1wvvzXEn7td999N+eeey6//e1vWbp0KX379i20XoCrr76aIUOGAJCWlpb3IHAqELnumwcftJZ6JIEY6elw/PFw4omxty+J8JEGUWTLli3UqlWL2rVrs2bNGt55p8SDgIulR48eeW6YBQsWFOgaWrRoEfv27WPVqlWsWLGCFStWcMcddzB+/Hi6d+/OrFmz+OmnnwDYuHEjAH369OGpp54CTJw3bdpEpUqVqFu3LkuWLCEnJ4dJkyYVatfmzZtp0sQiZ1955ZW87X369OHZZ59l3759B5zv6KOPpkGDBjzwwANceeWVZbspTuKSlgb79lkHa3GsXQsffWTHuNumRLjQR5GTTjqJtm3b0r59e6677jq6xyCj3i233MKqVavo0KEDDz/8MO3bt+fwww8/oMzYsWMZNGjQAduGDBnC2LFjadSoEc8++ywDBgygY8eOXHLJJQDcd999rFu3jvbt29OpU6c8d9I//vEP+vbtS+/evWnatGmhdt15553ccccdB13zb37zGxo3bkyHDh3o2LHjAR2uF198MS1atOC4444r0z1xEpiOHeG44yJLXTxhAqh6tE0pkEhdAeVFSkqKZmZmHrDtu+++o02bNgFZFF9kZ2eTnZ1N9erVWbJkCX369GHJkiUJGd54ww030K1bN64oaXhdPvz/I8G55x74+99h9WqbKaowzjjDInS+/bb8bEsgRGSOqqYUtM9b9AnGtm3b6N69Ox07dmTIkCE899xzCSnynTp1YvHixQwfPjxoU5ygSUuzDtaJEwsvs2oVfPqpd8KWksRTiApOnTp1mDNnTtBmlJlvoj0Ywklc2rWDNm3MffPb3xZc5vXX3W1TBrxF7zhOsIhYS/2TT8x9UxAZGebPP/748rUtSXChdxwneFJTrcU+YcLB+/73P/j8c3fblAEXesdxgqdNG4uNLygNRihVhrttSo8LveM48UFaGnz2GaxceeD29HQbRduqVTB2JQEu9BHQq1evgwY/PfbYY/y2sI6jEDVr1gRsVOrQoUMLrTt/OGl+HnvsMXbs2JG3ft555+UlGosGHTt29OgXJ3hyW+zh7psff4SvvvLWfBlxoY+A4cOH5yX/ymX8+PERi+NRRx3FhIJ8jxGSX+inT59OnTp1Sl1fON999x05OTl8/PHHbN++PSp1FkRxeXMch9atLSNl+OCpXFeOC32ZSDyhv/VW6NUrusuttxZ5yqFDh/LWW2+xe/duwDJDrl69mh49erBt2zZ69+7NSSedxIknnsiUAiZSWLFiBe3btwdg586dDBs2jA4dOpCWlsbOnTvzyt14442kpKTQrl077rvvPgCeeOIJVq9ezZlnnsmZZ54JQPPmzfnll18AeOSRR2jfvj3t27fnsVDGtxUrVtCmTRuuu+462rVrR58+fQ44Tzhjx47lsssuo0+fPkwNm8Nz6dKlnH322XTs2JGTTjopL1nZ6NGjOfHEE+nYsSMjR44EDnwr+eWXX2jevDlgqRAuuugiLrzwQvr06VPkvfrXv/6VN3r2sssuY+vWrbRo0YK9e/cCll6iefPmeetOkpKaCrNnQyiJH+nplrs+9D/llA6Po4+A+vXr07VrV95++20GDBjA+PHjSUtLQ0SoXr06kyZNonbt2vzyyy+ceuqp9O/fv9C5TJ999llq1KjB/PnzmT9/PieddFLevvvvv5969eqxb98+evfuzfz58xkxYgSPPPIIH3zwAQ0aNDigrjlz5vDyyy8ze/ZsVJVTTjmFnj175uWnGTduHC+88AKpqalMnDiRSy+99CB70tPTmTlzJosXL+app57Ke0u55JJLGDlyJIMGDWLXrl3k5OQwY8YMJk+ezOzZs6lRo0Ze3pqi+Pzzz5k/fz716tUjOzu7wHu1aNEi7r//fj777DMaNGjAxo0bqVWrFr169WLatGkMHDiQ8ePHM2TIEKpWrVqSr85JNFJT4a67rAN24ECYOxcefjhoqxKexBP6gPIU57pvcoU+N4e8qvLHP/6Rjz/+mEqVKrFq1SrWrVuXN8lHfj7++GNGjBgBQIcOHejQoUPevoyMDJ5//nmys7NZs2YNixYtOmB/fj799FMGDRqUl0Vy8ODBfPLJJ/Tv358WLVrkTUYSnuY4nK+++oqGDRtyzDHH0LRpU66++mo2bdpElSpVWLVqVV6+nOrVqwOWcviqq66iRo0awP6Uw0Vxzjnn5JUr7F7NmjWLoUOH5j3Icstfe+21jB49moEDB/Lyyy/zwgsvFHs+J8Fp2dLmgU1Pt6kGAS66KFibkoDEc90ExMCBA3n//ffzZo/KbYm/9tprrF+/njlz5vDNN9/QqFGjAlMTh1NQa//HH3/koYce4v3332f+/Pmcf/75xdZTVJ6i3BTHUHgq5HHjxvH999/TvHlzWrVqxZYtW5g4cWKh9RaWcrhKlSrk5OQARacyLuxeFVZv9+7dWbFiBR999BH79u3Lc385SU5qKsyZA888A6edBkcfXfwxTpG40EdIzZo16dWrF1dfffUBnbCbN2/miCOOoGrVqnzwwQd56X8L44wzzsibAPzbb79l/vz5gPmgDzvsMA4//HDWrVvHjBkz8o6pVasWW7duLbCuyZMns2PHDrZv386kSZM4/fTTI7qenJwcXn/9debPn5+XynjKlCmMGzeO2rVr07Rp07yJSHbv3s2OHTvo06cPL730Ul7HcK7rpnnz5nlpGYrqdC7sXvXu3ZuMjIy8GafCXUKXX345w4cP9xmoKhK5LfjVq32QVJRwoS8Bw4cPZ968eQwbNixv2yWXXEJmZiYpKSm89tprnHDCCUXWceONN7Jt2zY6dOjA6NGj6dq1K2Ahjp07d6Zdu3ZcffXVB6T7vf766+nXr19eZ2wuJ510EldeeSVdu3bllFNO4dprr6VzhPNofvzxxzRp0iQvhzzYg2PRokWsWbOGf//73zzxxBN06NCB0047jbVr19K3b1/69+9PSkoKnTp14qGHHgLg9ttv59lnn+W0007L6yQuiMLumNAa9AAABTdJREFUVbt27bj77rvp2bMnHTt25A9/+MMBx2zatMnDPysSxxwDp55qqREKCUt2SoanKXbimgkTJjBlyhT+/e9/F1rG/z+SkI8+so7YYiLinP0UlaY48TpjnQrDLbfcwowZM5g+fXrxhZ3komdPW5yoEJHQi0hf4HGgMjBGVR/It/8G4CZgH7ANuF5VF4lIc+A7YHGo6BeqekN0THeSnSeffDJoExwnKShW6EWkMvA0cA6QBXwlIlNVNXyy0rGq+s9Q+f7AI0Df0L5lqtqprIYWFpnhVGzizfXoOPFIJJ2xXYGlqrpcVfcA44EB4QVUdUvY6mFAVH991atXZ8OGDf6jdg5AVdmwYUNenL/jOAUTieumCRCeTi4LOCV/IRG5CfgDUA04K2xXCxGZC2wB/qSqnxRw7PXA9QDNmjU7yICmTZuSlZXF+vXrIzDXqUhUr169yEnLHceJTOgL8pcc1LRW1aeBp0XkYuBPwBXAGqCZqm4QkS7AZBFpl+8NAFV9HngeLOomf91Vq1alRYsWEZjqOI7j5CcS100WED40rSlQyHxfgLl2BgKo6m5V3RD6PAdYBhxXOlMdx3Gc0hCJ0H8FtBaRFiJSDRgGTA0vICKtw1bPB5aEtjcMdeYiIi2B1sDyaBjuOI7jREaxrhtVzRaRm4F3sPDKl1R1oYiMAjJVdSpws4icDewFNmFuG4AzgFEiko2FXt6gqsWnPHQcx3GiRtyNjBWR9UDRCWOKpgFQ+Dj85KSiXXNFu17wa64olOWaj1HVhgXtiDuhLysiklnYMOBkpaJdc0W7XvBrrijE6po9qZnjOE6S40LvOI6T5CSj0D8ftAEBUNGuuaJdL/g1VxRics1J56N3HMdxDiQZW/SO4zhOGC70juM4SU7SCL2IvCQiP4vIt0HbUh6IyNEi8oGIfCciC0Xkd0HbFGtEpLqIfCki80LX/JegbSovRKSyiMwVkbeCtqU8EJEVIrJARL4Rkczij0h8RKSOiEwQke9Dv+tuUas7WXz0InIGNunJv1S1fdD2xBoRORI4UlW/FpFawBxgYL55ApIKsQkJDlPVbSJSFfgU+J2qfhGwaTFHRP4ApAC1VfWCoO2JNSKyAkhR1QozYEpEXgU+UdUxoXQzNVT112jUnTQtelX9GKgw6RVUdY2qfh36vBWbyatJ0UclNmpsC61WDS3J0VIpAhFpiuWQGhO0LU5sEJHaWMqYFwFUdU+0RB6SSOgrMqEpGzsDs4O1JPaEXBjfAD8DM1U16a8ZeAz4PyAnaEPKEQXeFZE5ofkqkp2WwHrg5ZCLboyIHBatyl3oExwRqQlMBG7Nn+c/GVHVfaGpKZsCXUUkqd10InIB8HMozXdForuqngT0A24KuWaTmSrAScCzqtoZ2A6MjFblLvQJTMhPPRF4TVXfCNqe8iT0Wvsh++cmTla6A/1DPuvxwFki8p9gTYo9qro69PdnYBI2pWkykwVkhb2hTsCEPyq40CcooY7JF4HvVPWRoO0pD0LzG9QJfT4UOBv4PlirYouq3qWqTVW1OTYXxCxVvTRgs2KKiBwWCjAg5L7oAyR1NJ2qrgVWisjxoU29gagFVkQylWBCICLjgF5AAxHJAu5T1ReDtSqmdAcuAxaEfNYAf1TV6QHaFGuOBF4NTWZTCchQ1QoRbljBaARMsrYMVYCxqvp2sCaVC7cAr4UibpYDV0Wr4qQJr3Qcx3EKxl03juM4SY4LveM4TpLjQu84jpPkuNA7juMkOS70juM4SY4LveM4TpLjQu84jpPk/H8isuYBvVthuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train and val accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.savefig('/1-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and val loss\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('/1-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
